{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bQUGQr0kknZy"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.37.2\n",
        "!pip install bitsandbytes==0.41.3 accelerate==0.25.0\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install gradio\n",
        "!pip install gTTS\n",
        "!pip install huggingface_hub\n",
        "!pip install bark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpYRy06CkvJ0"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoProcessor, AutoModel\n",
        "import torch\n",
        "import whisper\n",
        "import gradio as gr\n",
        "import warnings\n",
        "import librosa\n",
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a903P5Wok0xp"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfG8Dwnxk01J"
      },
      "outputs": [],
      "source": [
        "# CUDA Check\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using torch {torch.__version__} ({DEVICE})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1rIGW8Zk05g"
      },
      "outputs": [],
      "source": [
        "# Load Whisper model for Speech-to-Text\n",
        "model_whisper = whisper.load_model(\"medium\", device=DEVICE)\n",
        "print(f\"Whisper model loaded with {sum(np.prod(p.shape) for p in model_whisper.parameters()):,} parameters.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGq9TYd8k08T"
      },
      "outputs": [],
      "source": [
        "# Load Text Generation model (NVIDIA Mistral)\n",
        "model_id = \"google/flan-t5-large\"\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"quantization_config\": quant_config}\n",
        ")\n",
        "print(f\"Loaded Text Generation model: {model_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJuZYFtahKQM"
      },
      "outputs": [],
      "source": [
        "# Load Bark model and processor\n",
        "processor = AutoProcessor.from_pretrained(\"suno/bark-small\")\n",
        "model = AutoModel.from_pretrained(\"suno/bark-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7oEON-biwtT"
      },
      "outputs": [],
      "source": [
        "# Define speaker options\n",
        "SPEAKERS = {\n",
        "    \"english-male-1\": \"v2/en_speaker_1\",\n",
        "    \"english-male-2\": \"v2/en_speaker_2\",\n",
        "    \"english-female\": \"v2/en_speaker_9\",\n",
        "    \"hindi-male-1\": \"v2/hi_speaker_2\",\n",
        "    \"hindi-male-2\": \"v2/hi_speaker_5\",\n",
        "    \"hindi-female-1\": \"v2/hi_speaker_0\",\n",
        "    \"hindi-female-2\": \"v2/hi_speaker_4\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9b70rIok0-w"
      },
      "outputs": [],
      "source": [
        "# Convert audio format to 16kHz mono using librosa\n",
        "def convert_audio_to_whisper_format(audio_path):\n",
        "    audio, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
        "    processed_audio_path = \"processed_audio.wav\"\n",
        "    sf.write(processed_audio_path, audio, sr)\n",
        "    return processed_audio_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWjqDFybZeFv"
      },
      "outputs": [],
      "source": [
        "# Transcribe function using Whisper\n",
        "def transcribe(audio):\n",
        "    if audio is None or audio == '':\n",
        "        return ''  # Return empty string if no audio input\n",
        "\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(whisper_model.device)\n",
        "    result = whisper.decode(whisper_model, mel)\n",
        "    return result.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_iY73ZPk1BP"
      },
      "outputs": [],
      "source": [
        "# Text-to-Speech conversion using Bark with speaker selection\n",
        "def text_to_speech_bark(text, speaker_id, file_path=\"output.wav\"):\n",
        "    inputs = processor(text, return_tensors=\"pt\")\n",
        "    inputs[\"speaker_embeddings\"] = bark_model.get_speaker_embeddings(speaker_id)\n",
        "    audio_array = bark_model.generate(inputs)\n",
        "    sf.write(file_path, audio_array.cpu().numpy(), 24000)\n",
        "    return file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffF17FNfk1Dq"
      },
      "outputs": [],
      "source": [
        "def process_audio(audio_path, speaker):\n",
        "    # Step 1: Transcribe audio\n",
        "    speech_to_text_output = transcribe(audio_path)\n",
        "\n",
        "    if not speech_to_text_output.strip():\n",
        "        return \"No speech detected.\", \"No response generated.\", None\n",
        "\n",
        "    # Step 2: Add instruction to LLM input\n",
        "    llm_instruction = \"You are an AI assistant. Answer the questions asked accurately and concisely.\"\n",
        "    llm_input = f\"{llm_instruction}\\nUser: {speech_to_text_output}\"\n",
        "\n",
        "    # Step 3: Generate LLM response\n",
        "    llm_response = pipe(llm_input)[0]['generated_text']\n",
        "\n",
        "    # Step 4: Convert LLM response to speech using Bark\n",
        "    processed_audio_path = text_to_speech_bark(llm_response, SPEAKERS[speaker])\n",
        "\n",
        "    return speech_to_text_output, llm_response, processed_audio_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wljs8W-6lsh3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVQWfnxRk1F4"
      },
      "outputs": [],
      "source": [
        "def clear_inputs():\n",
        "    return None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Cip3XWcZKwo"
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    audio_input = gr.Audio(type=\"filepath\", label=\"Record your voice\")\n",
        "    speaker_dropdown = gr.Dropdown(choices=list(SPEAKERS.keys()), label=\"Select Speaker\", value=\"english-male-1\")\n",
        "    transcript_output = gr.Textbox(label=\"Speech to Text\")\n",
        "    llm_output = gr.Textbox(label=\"LLM Response\")\n",
        "    audio_output = gr.Audio(label=\"Response as Audio\")\n",
        "\n",
        "    process_btn = gr.Button(\"Process Audio\")\n",
        "    clear_btn = gr.Button(\"Clear\")\n",
        "\n",
        "    process_btn.click(process_audio, inputs=[audio_input, speaker_dropdown], outputs=[transcript_output, llm_output, audio_output])\n",
        "    clear_btn.click(clear_inputs, outputs=[audio_input, transcript_output, llm_output, audio_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xmM98Qba4ky"
      },
      "outputs": [],
      "source": [
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}